# DAD-NNN-Val

# Fiche Pédagogique

## Informations Étudiant

- **Nom :** Yong 

- **Prénom :** Jeyeon (Valérie)

  

## Profil et Connaissances

### Présentation Personnelle

//Décrivez en quelques phrases vos objectifs à cours terme et long terme si vou en avez : 

Faire le master dans le domaine de DAD si possible dans une autre pays (mais celle de ESAD m'intéresse aussi donc ça sera mon plan B), puis le doctorat pour être une professeur de l’université. Après avoir eu suffisamment d’expérience et de career, retourne en Corée si je trouve la place pour le prof de l’université.


### Compétences Actuelles

### Compétences :

// notez vous avec une note entre 0 et 20 pour chaque compétence et rajoutez une petite description 

**CODING** 14 (à l'aise avec html et css, niveau intermédiaire en JavaScript et PHP)

**GIT ET VERSIONNING** 0 (je ne savais pas ce que c'est)

**INTERACTIVITÉ ET RENDU TEMPS RÉEL** 9 (j'ai déjà fait un peu d'interactivité, mais peu de rendu en temps réel. Je n'ai pas encore trop confiance en moi pour le rendu en temps réel)

**GRAPHISME ET DESIGN D'INTERFACE** 13 (j'ai les connaissances et les compétences nécessaires, je trouve que je fait des designs propres, mais il me manque un peu de prise de risque et d'idées innovantes)

**INSTALLATION ET MISE EN ESPACE** 14 (je sais installer proprement et organiser avec une certaine logique pour que l'espace soit cohérent quand on y circule, mais sans rien de particulièrement impressionnant)

**PRÉSENTATION ET ARGUMENTATION** 12.75 (je présente bien avec une préparation suffisante, en établissant des liens entre les différentes œuvres. Je résume bien en sélectionnant les informations à expliquer dans le temps imparti. MAIS je suis nul en improvisation et en réponses aux questions imprévues) 



## Projet et Thématique de Recherche

# Projet 1

### Sujet de Projet

- **Titre du projet :**  Be happy to stop the alarm!
- **Description du projet (environ 150 mots) :**  
Nous avons tous du mal à nous lever chaque matin, et les alarmes classiques ne rendent pas les choses plus agréables. C'est en partant de ce constat que j'ai développé une alarme qui transforme le réveil en un moment plus positif. Cette alarme ne peut être arrêtée qu’en souriant pendant trois secondes qui est détectée par l'IA, ce qui non seulement la rend moins stressée mais aussi efficace pour débuter la journée sur une note positive. 
Chaque fois que je testais la détection de mon sourire, cela me faisait sourire, ce qui m’a aidé à rester concentré et détendu, même lorsque j'étais frustré. Cette idée a évolué en une alarme basée sur la reconnaissance faciale.


### Thématiques de Recherche

- **Thématiques que vous souhaitez explorer :**  Questionner la présence des IA dans notre quotidien.
- **Pourquoi cette thématique vous intéresse-t-elle ? (environ 100 mots) :**
Cette thématique m'intéresse parce que l'IA a un potentiel pour améliorer notre quotidien, et j'aime l'idée de l'exploiter de façon ludique et accessible. En ajoutant une touche d'humour, j’espère transformer des tâches banales ou même désagréables en expériences plus légères et engageantes. Je souhaite explorer et utiliser les compétences technologiques qui évoluent avec nous et enrichissent notre quotidien. Je m’inspire de Bruce Mazlish, qui, dans The Fourth Discontinuity, affirme que l’Homme n'est plus seulement le créateur des machines, mais qu'il co-évolue en symbiose avec elles.


## Outils et Techniques

- **Outils que vous comptez utiliser (logiciels, langages de programmation, etc.) :**  ml5, linux, raspberry pi, une horloge mécanique, python, TFLite, deep learning
- **Techniques spécifiques que vous souhaitez maîtriser ou expérimenter :** linux, raspberry pi

## Références Artistiques

- **Argumentaire expliquant la pertinence de votre projet (environ 150 mots) :**   En ajoutant une touche d'humour, je transforme des tâches banales du quotidien en nouvelles expériences, notamment en utilisant les nouvelles technologies. Je me suis inspiré du Chindogu de Kenji Kawakami, qui consiste à réinventer des objets qui semblent être des solutions idéales à des problèmes quotidiens avec un côté humoristique et un peu  étrange. 
Mon projet se réfère à Charlie Chaplin dans Les Temps modernes, de « sourire » même face au désespoir, même si c’est un sourire forcé. 

- **Références artistiques qui inspirent votre travail (livres, artistes, œuvres, etc.) :**
  - The Unuseless Inventions of Kenji Kawakami
  - Les Temps modernes, Charlie Chaplin - smile forcé
  - Kim Le Boutin https://www.instagram.com/kimbtn_/
  - Temporary Autonomous Zone - Hakim Bey
  - Hypernormalisation | Full Documentary | Adam Curtis https://www.youtube.com/watch?v=Gr7T07WfIhM
  - ENIAROF https://www.eniarof.com/


# Projet 2

### Sujet de Projet

- **Titre du projet :**  Don't move to listen to the music!
- **Description du projet (environ 150 mots) :** 
Pour moi, il est impossible de contempler la musique si je suis occupé à faire autre chose. Dans ces moments-là, la musique se transforme comme un bruit blanc, et je finis par oublier complètement que je l’écoute.
Dans ce projet, l’IA détecte les mouvements corporels. Si un grand mouvement est capté, la musique devient floue ou se transforme en un bruit blanc, symbolisant la distraction. En contraire, lorsque la persone reste immobile, la musique reprend sa clarté et peut être pleinement appréciée.
C'est-à-dire qu'il faut pas bouger pour contempler la musique.


### Thématiques de Recherche

- **Thématiques que vous souhaitez explorer :**   Comment créer des expériences contemplatives musicales ?
- **Pourquoi cette thématique vous intéresse-t-elle ? (environ 100 mots) :** J’ai choisi ce sujet car il combine deux éléments qui me passionnent : la création d’expériences uniques et la musique. J’aime créer des expériences uniques pour les autres, des moments que j’ai moi-même vécus. Le thème de la musique m’a attiré particulièrement, car j’ai déjà travaillé sur des projets liés au son et aux musiques, et je souhaite approfondir cette exploration.


## Outils et Techniques

- **Outils que vous comptez utiliser (logiciels, langages de programmation, etc.) :**  python? p5js? 
- **Techniques spécifiques que vous souhaitez maîtriser ou expérimenter :** TouchDesigner

## Références Artistiques

- **Argumentaire expliquant la pertinence de votre projet (environ 150 mots) :**   
- **Références artistiques qui inspirent votre travail (livres, artistes, œuvres, etc.) :**
  - https://www.instagram.com/reel/DBXGrR7yubD/ → Using the #MediaPipe plugin in #TouchDesigner, it tracks hand movements and extracts the coordinates of the thumb and index fingertips, then calculates the hand’s open or closed state. When the hand opens, an audio signal is triggered and sent to #VCVRack, generating string sounds and randomly delayed chimes. The sound changes based on the coordinates, such as: the wider the fingers open, the louder the sound; moving to the right strengthens the delay effect; moving upwards raises the pitch; rotating changes the left-right stereo balance.
  - https://www.instagram.com/reel/DBsNdCUpNc9/ → "It was made using the mediapipe plugin for touchdesigner by @blankensmithing ! i doubt i could make a better setup tutorial than his — if you search up “free motion tracking mediapipe touchdesigner” you should find the video. oh also the way i use it with ableton is through a thing called “TDAbleton” which im sure there’s many good tutorials out there for"
  - [Tutorial] Movement Controlled Instruments – TouchDesigner, Ableton Live and Kinect https://www.youtube.com/watch?v=vHtUXvb6XMM


## Actions

### Contribution à un Projet d'Autre Étudiant

// Décrivez comment vous comptez contribuer au projet d'un autre étudiant (proposition d'idées, aide technique, etc.) : 
Je compte contribuer au projet d'un autre étudiant en apportant mes compétences et mon expérience dans des domaines complémentaires au sien. Par exemple, je peux partager mes connaissances techniques sur le code.

### **CRÉATION D'UN SUJET DE RECHERCHE**
~~Utiliser l'IA comme assistant au quotidien, avec une approche teintée d’humour.~~

Questionner la présence des IA dans notre quotidien.

### Participation à un Sujet de Recherche

Comment créer des expériences contemplatives musicales ? - Émilie

### Contributions aux ressources

Des ressources communes seront alimentées par tous. Chaque étudiant devra contribuer et enrichir cet ensemble de ressources.

### **PRÉSENTATION DE 20 MINUTES SUR UN SUJET ARTISTIQUE/DESIGN (RECHERCHE THÉORIQUE)**

Présentation sur la découverte de la liste de code de python: https://github.com/bnsreenu/python_for_microscopists + deep learning

## Commentaires et Questions

//Avez-vous des questions ou des préoccupations à propos du cours ou de vos projets ? : 





# Journal de bord

### 29.10.2024
**Planning de Travail :** 
- Trouver un artiste préférée
  - Aram Bartholl https://arambartholl.com/ 
  - Kyle Mcdonald https://kylemcdonald.net/ 
- sujet de recherche : l’IA qui nous “aide” + humour? 
- Quelles aides? A préciser. → quotidien? 

**Idée :** 
- Jeu consolable seulement par les émotions faciales qui peut être bénéficier pour les handicapés. J’ai été inspiré par le jeu jouable seulement avec les  yeux : Eyes First games https://www.microsoft.com/en-us/research/product/eyes-first/ 
  - Anger for Attack
  - Fear and Disgust for Go Back
  - Happiness for Go Forward
  - Surprise for Jump
  - Sadness for Crouch

*ou Idle Game comme Universal Paperclips* 

- Alarme qu’on peut seulement éteindre avec nos sourire (pendant 3 sec) → design 
- Conversation avec l'extraterrestre (utilisation de l'IA) 
- Something with sport?


### 30.10.2024 ~ 04.11.2024
- Finir le code pour l'alarme → https://editor.p5js.org/valyong/sketches/d7zULvvOu 
- Concrétiser ma positionnement sur le sujet de recherche


### 05.11.2024
**Planning de Travail :** 
- Alarme design → INTERACTIVITÉ ET RENDU TEMPS RÉEL & GRAPHISME ET DESIGN D'INTERFACE
<img src="/img/alarme_sketch1.jpg" height="500">
- Chercher des refs pour Alarme
- Alarme écrire la description du projet
- sujet de recherche


### 12.11.2024
**Planning de Travail :** 
1. Tensorflow Lite → trouver python emotion detection 
2. Installer linux et le découvrir (Ubuntu)
3. ml5 sur linux
4. quel code faut-il utiliser (voir avec Robin) 
5. dessin design horloge mécanique (iconographique, caricaturale, machine)
6. Trouvé une horloge (le bon coin, vinted, resources AAA, etc)

- How to Run TensorFlow Lite Models on Windows https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/deploy_guides/Windows_TFLite_Guide.md
- TensorFlow Lite Object Detection on Android and Raspberry Pi https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi?tab=readme-ov-file#step-3-run-tensorflow-lite-models
- How to Run TensorFlow Lite Object Detection Models on the Raspberry Pi (with Optional Coral USB Accelerator) https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/deploy_guides/Raspberry_Pi_Guide.md
- Youtube How To Run TensorFlow Lite on Raspberry Pi for Object Detection https://www.youtube.com/watch?app=desktop&v=aimSGOAUI8Y

**Ce que j'ai réalisé :** 
Test pour tflite python → détection des élements sur les images, videos et webcam
<img src="/img/animals.jpg" height="300">
<img src="/img/squirrel.jpg" height="300">
<img src="/img/webcam-test.png" height="400">

### 19.11.2024
**Ce que j'ai réalisé :** 
Python emotion detection → deep learning : 
- L'ensemble d'entraînement comprend 28 709 exemples et l'ensemble de test public comprend 3 589 exemples.
- Dataset : https://www.kaggle.com/datasets/msambare/fer2013 
- video suivi : https://www.youtube.com/watch?v=P4OevrwTq78&t=352s
- Liste de code de python: https://github.com/bnsreenu/python_for_microscopists 


Puis testé le modèle que j'ai entraîné avec le webcam : 
1. Set environment : conda activate emotion_detection / set cd 
2. Le modèle entraîné enregistré sous forme de fichier emotion_detection_model_100epochs.h5
3. Assurez-vous que les bibliothèques suivantes sont installées dans votre environnement : pip install opencv-python-headless numpy keras tensorflow
4. Code pour tester avec la webcam : emotion_webcam.py (aide de ChatGPT)
5. Exécutez le script : python emotion_webcam.py
<img src="/img/emotion-detection.png" height="400">

### 26.11.2024
**Aide**
- Par Anne-Sophie → donner un ref https://www.domesticstreamers.com/art-research/work/730-hours-of-violence/
- À Anne-Sophie → Code Processing pour glitch d'une image

**À faire**
- Tester Rasberry Pi → https://www.raspberrypi.com/documentation/computers/getting-started.html#install-an-operating-system
<img src="/img/rasberry-setting.png" height="400">

### 28.11.2024, 01.12.2024
**Ce que j'ai réalisé :** 
Python pour alarme (lance le son d'alarme et s'éteint quand il détecte Happy)
Dans python :
- pip install pygame, une bibliothèque utilisée pour créer des jeux vidéo et des applications multimédias en Python, dont je peux jouer des sonsdans divers formats (comme .mp3, .wav)
- pip install tflite-runtime

  
- source tflite1-env/bin/activate
<img src="/img/happy_detected.png" height="400">

- Installer TensorFlow Lite sur Raspberry Pi : https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/deploy_guides/Raspberry_Pi_Guide.md
<img src="/img/rasberry.jpg" height="400">
- Convert from h5 file to tflite for rasberry pi
<img src="/img/convert.png" height="200">

- Design : typo classique qui convient bien avec le thème mécanique et classique mais composition moderne et simple

<img src="/img/horloge-design1.jpg" height="240"> <img src="/img/horloge-design2.jpg" height="240">
<img src="/img/horloge-design3.jpg" height="240"> <img src="/img/horloge-design4.jpg" height="240">  
<img src="/img/horloge-design5.jpg" height="240"> 

### 03.12.2024
**À faire**
- Démonter l'alarme
- Découvrir TrouchDesigner
- <img src="/img/shindogu1.png" height="240"> <img src="/img/shindogu2.png" height="240">
<img src="/img/shindogu3.png" height="240">  <img src="/img/shindogu4.png" height="240">  <img src="/img/shindogu5.png" height="240">

→ Projet 2 "Don't move to listen to the music!" > Comment créer des expériences contemplatives musicales ? 

**Ce que j'ai réalisé :** 
- Démonter l'alarme

<img src="/img/horloge.jpg" height="300"> <img src="/img/sketch1.jpg" height="300"> <img src="/img/sketch2.jpg" height="300">
- Tester python alarme sur rasberry pi (avec les images car il y a pas de webcam à ESAD) → ça marche
- Discuter avec Eda sur les autres sujets de recherches pour trouver l'idée. Eda m'a aider à penser sur le sujet "Comment créer des expériences contemplatives musicales".

### 10.12.2024
- tester le camera : libcamera-hello

**Ce que j'ai réalisé :** 
- imprimer le design d'alarme
- changer le script cv2.VideoCapture(0) → Picamera2 (il faut installer python3-picamera2) , car picamera2 est designer pour interagir avec libcamera
- Add the libcamera shared library path to your environment:
  export LD_LIBRARY_PATH=/usr/lib/arm-linux-gnueabihf/:$LD_LIBRARY_PATH
  export PYTHONPATH=/usr/lib/python3/dist-packages:$PYTHONPATH

lancer le script : 
- cd /home/yongb/tflite1
- source tflite1-env/bin/activate
- export LD_LIBRARY_PATH=/usr/lib/arm-linux-gnueabihf/:$LD_LIBRARY_PATH export PYTHONPATH=/usr/lib/python3/dist-packages:$PYTHONPATH
- python alarm.py

<img src="/img/picamera-success.jpg" height="500"> <img src="/img/script.jpg" height="500">

- Pourquoi détecter en Grayscale? → pour simplifier et accélérer le traitement. Les algorithmes de détection de visage (haarcascades) et les modèles de reconnaissance d'émotions se concentrent sur les formes et les contrastes, pas sur les couleurs. De plus, cela réduit la quantité de données à analyser, ce qui est essentiel pour un traitement en temps réel.
- haarcascade_frontalface_default.xml : modèle de détection de visages
Ce modèle repose sur des "caractéristiques Haar" pour analyser des motifs dans l'image (par exemple, des contrastes clairs/foncés entre les yeux et le nez).
  - https://github.com/opencv/opencv/tree/master/data/haarcascades
- emotion_detection_model.tflite : modèle d'apprentissage profond qui a été formé pour prédire les émotions à partir de l'image du visage.

### 06.01.2025
**Ce que j'ai réalisé :** 
- finalisation de monter l'horloge

<img src="/img/horloge-processus.jpg" height="300">  <img src="/img/horloge1.jpg" height="300">  <img src="/img/horloge2.jpg" height="300">
<img src="/img/horloge3.jpg" height="300">
- chercher comment run python script on start up in raspberry
  - https://www.samwestby.com/tutorials/rpi-startupscript.html
  - https://www.instructables.com/Raspberry-Pi-Launch-Python-script-on-startup/
- chercher comment controler DC moteur avec raspberry
  - https://www.raspberrypi-france.fr/comment-utiliser-les-port-gpio-raspberry-pi/
  - https://www.youtube.com/watch?v=a99SiwFRcUI
- repenser sur ma positionnement : nouvelles pratiques des nouveaux techniques (non pas l'innovation)

### 07.01.2025
**Ce que j'ai réalisé :** 
- aider Jolaine pour l'ouverture de la porte sur Unity → fail...TT
- tourner le caméra 180°
- run python script on start up
- penser à l'accrochage
<img src="/img/accrochage.jpg" height="400">

### 08.01.2025
- souder les diodes
- testerle moteur  Fail
- prendre des photos de mise en situation
- accrochage
