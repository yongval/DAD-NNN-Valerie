# DAD-NNN-Val

# Fiche Pédagogique

## Informations Étudiant

- **Nom :** Yong 

- **Prénom :** Jeyeon (Valérie)

  

## Profil et Connaissances

### Présentation Personnelle

//Décrivez en quelques phrases vos objectifs à cours terme et long terme si vou en avez : 

Faire le master dans le domaine de DAD si possible dans une autre pays (mais celle de ESAD m'intéresse aussi donc ça sera mon plan B), puis le doctorat pour être une professeur de l’université. Après avoir eu suffisamment d’expérience et de career, retourne en Corée si je trouve la place pour le prof de l’université.


### Compétences Actuelles

### Compétences :

// notez vous avec une note entre 0 et 20 pour chaque compétence et rajoutez une petite description 

**CODING** 14 (à l'aise avec html et css, niveau intermédiaire en JavaScript et PHP)

**GIT ET VERSIONNING** 0 (je ne savais pas ce que c'est)

**INTERACTIVITÉ ET RENDU TEMPS RÉEL** 9 (j'ai déjà fait un peu d'interactivité, mais peu de rendu en temps réel. Je n'ai pas encore trop confiance en moi pour le rendu en temps réel)

**GRAPHISME ET DESIGN D'INTERFACE** 13 (j'ai les connaissances et les compétences nécessaires, je trouve que je fait des designs propres, mais il me manque un peu de prise de risque et d'idées innovantes)

**INSTALLATION ET MISE EN ESPACE** 14 (je sais installer proprement et organiser avec une certaine logique pour que l'espace soit cohérent quand on y circule, mais sans rien de particulièrement impressionnant)

**PRÉSENTATION ET ARGUMENTATION** 12.75 (je présente bien avec une préparation suffisante, en établissant des liens entre les différentes œuvres. Je résume bien en sélectionnant les informations à expliquer dans le temps imparti. MAIS je suis nul en improvisation et en réponses aux questions imprévues) 



## Projet et Thématique de Recherche

# Projet 1

### Sujet de Projet

- **Titre du projet :**  Be happy to stop the alarm!
- **Description du projet (environ 150 mots) :**  
Nous avons tous du mal à nous lever chaque matin, et les alarmes classiques ne rendent pas les choses plus agréables. C'est en partant de ce constat que j'ai développé une alarme qui transforme le réveil en un moment plus positif. Cette alarme ne peut être arrêtée qu’en souriant pendant trois secondes qui est détectée par l'IA, ce qui non seulement la rend moins stressée mais aussi efficace pour débuter la journée sur une note positive. 
Chaque fois que je testais la détection de mon sourire, cela me faisait sourire, ce qui m’a aidé à rester concentré et détendu, même lorsque j'étais frustré. Cette idée a évolué en une alarme basée sur la reconnaissance faciale, qui encourage un état d’esprit plus agréable dès le réveil.


### Thématiques de Recherche

- **Thématiques que vous souhaitez explorer :**  
- **Pourquoi cette thématique vous intéresse-t-elle ? (environ 100 mots) :**
Cette thématique m'intéresse parce que l'IA a un potentiel immense pour améliorer notre quotidien, et j'aime l'idée de l'exploiter de façon ludique et accessible. En ajoutant une touche d'humour, j’espère transformer des tâches banales ou même désagréables en expériences plus légères et engageantes. Explorer l'IA sous cet angle permet aussi de démystifier la technologie, la rendant plus humaine et conviviale. Cela m'offre la possibilité de mêler créativité et innovation, pour concevoir des outils utiles, drôles et stimulants. Je souhaite explorer les compétences technologiques qui évoluent avec nous et enrichissent notre quotidien. Je m’inspire de Bruce Mazlish, qui, dans The Fourth Discontinuity, affirme que l’Homme n'est plus seulement le créateur des machines, mais qu'il co-évolue en symbiose avec elles.


## Outils et Techniques

- **Outils que vous comptez utiliser (logiciels, langages de programmation, etc.) :**  ml5, linux, raspberry pi, une horloge mécanique, python, TFLite
- **Techniques spécifiques que vous souhaitez maîtriser ou expérimenter :** linux, raspberry pi

## Références Artistiques

- **Argumentaire expliquant la pertinence de votre projet (environ 150 mots) :**   Comme le conseil de Charlie Chaplin de *« sourire »* même face au désespoir, comme on le voit dans *Les Temps modernes*, j'ai voulu transmettre un message d'avancer vers un avenir incertain mais plein d'espoir, même si cela commence par un sourire forcé. Je me suis inspiré du Chindogu, la pratique qui consiste à inventer des gadgets ingénieux du quotidien qui semblent être des solutions idéales à des problèmes spécifiques, mais qui finissent souvent par causer plus de problèmes qu'ils n'en résolvent. Cependant, je souhaite aller plus loin en répondant à de petits problèmes quotidiens grâce à l'IA. En ajoutant une touche d'humour, parfois teintée d'une nuance dystopique, j'espère transformer des tâches banales, voire désagréables, en expériences plus légères et amusantes qui peuvent aussi inviter à la réflexion.
- **Références artistiques qui inspirent votre travail (livres, artistes, œuvres, etc.) :**
  - The Unuseless Inventions of Kenji Kawakami
  - Les Temps modernes, Charlie Chaplin - smile forcé
  - Kim Le Boutin https://www.instagram.com/kimbtn_/
  - Temporary Autonomous Zone - Hakim Bey
  - Hypernormalisation | Full Documentary | Adam Curtis https://www.youtube.com/watch?v=Gr7T07WfIhM
  - ENIAROF https://www.eniarof.com/


# Projet 2

### Sujet de Projet

- **Titre du projet :**  
- **Description du projet (environ 150 mots) :** Questionner la présence des IA dans notre quotidien.
Pour moi, il est impossible de contempler la musique si je suis occupé à faire autre chose. Dans ces moments-là, la musique se transforme comme un bruit blanc, et je finis par oublier complètement que je l’écoute.
Dans ce projet, l’IA détecte les mouvements corporels. Si un grand mouvement est capté, la musique devient floue ou se transforme en un bruit blanc, symbolisant la distraction. En contraire, lorsque la persone reste immobile, la musique reprend sa clarté et peut être pleinement appréciée.
C'est-à-dire qu'il faut pas bouger pour contempler la musique.


### Thématiques de Recherche

- **Thématiques que vous souhaitez explorer :**   Comment créer des expériences contemplatives musicales ?
- **Pourquoi cette thématique vous intéresse-t-elle ? (environ 100 mots) :** J’ai choisi ce sujet car il combine deux éléments qui me passionnent : la création d’expériences uniques et la musique. J’aime créer des expériences uniques pour les autres, des moments que j’ai moi-même vécus. Le thème de la musique m’a attiré particulièrement, car j’ai déjà travaillé sur des projets liés au son et aux musiques, et je souhaite approfondir cette exploration.


## Outils et Techniques

- **Outils que vous comptez utiliser (logiciels, langages de programmation, etc.) :**  
- **Techniques spécifiques que vous souhaitez maîtriser ou expérimenter :** TouchDesigner

## Références Artistiques

- **Argumentaire expliquant la pertinence de votre projet (environ 150 mots) :**   
- **Références artistiques qui inspirent votre travail (livres, artistes, œuvres, etc.) :**
  - https://www.instagram.com/reel/DBXGrR7yubD/ → Using the #MediaPipe plugin in #TouchDesigner, it tracks hand movements and extracts the coordinates of the thumb and index fingertips, then calculates the hand’s open or closed state. When the hand opens, an audio signal is triggered and sent to #VCVRack, generating string sounds and randomly delayed chimes. The sound changes based on the coordinates, such as: the wider the fingers open, the louder the sound; moving to the right strengthens the delay effect; moving upwards raises the pitch; rotating changes the left-right stereo balance.
  - https://www.instagram.com/reel/DBsNdCUpNc9/ → "It was made using the mediapipe plugin for touchdesigner by @blankensmithing ! i doubt i could make a better setup tutorial than his — if you search up “free motion tracking mediapipe touchdesigner” you should find the video. oh also the way i use it with ableton is through a thing called “TDAbleton” which im sure there’s many good tutorials out there for"
  - [Tutorial] Movement Controlled Instruments – TouchDesigner, Ableton Live and Kinect https://www.youtube.com/watch?v=vHtUXvb6XMM


## Actions

### Contribution à un Projet d'Autre Étudiant

// Décrivez comment vous comptez contribuer au projet d'un autre étudiant (proposition d'idées, aide technique, etc.) : 
Je compte contribuer au projet d'un autre étudiant en apportant mes compétences et mon expérience dans des domaines complémentaires au sien. Par exemple, je peux partager mes connaissances techniques sur le code.

### **CRÉATION D'UN SUJET DE RECHERCHE**
~~Utiliser l'IA comme assistant au quotidien, avec une approche teintée d’humour.~~

Questionner la présence des IA dans notre quotidien.

### Participation à un Sujet de Recherche

Comment créer des expériences contemplatives musicales ? - Émilie

### Contributions aux ressources

Des ressources communes seront alimentées par tous. Chaque étudiant devra contribuer et enrichir cet ensemble de ressources.

### **PRÉSENTATION DE 20 MINUTES SUR UN SUJET ARTISTIQUE/DESIGN (RECHERCHE THÉORIQUE)**

Présentation sur la découverte de la liste de code de python: https://github.com/bnsreenu/python_for_microscopists + deep learning

## Commentaires et Questions

//Avez-vous des questions ou des préoccupations à propos du cours ou de vos projets ? : 





# Journal de bord

### 29.10.2024
**Planning de Travail :** 
- Trouver un artiste préférée
  - Aram Bartholl https://arambartholl.com/ 
  - Kyle Mcdonald https://kylemcdonald.net/ 
- sujet de recherche : l’IA qui nous “aide” + humour? 
- Quelles aides? A préciser. → quotidien? 

**Ref :** 
- The Unuseless Inventions of Kenji Kawakami 
  - https://www.instagram.com/tonsil/reel/C4JQdfiOh1q/?locale=zh-hans&hl=fr 
  - https://www.lemonde.fr/arts/portfolio/2015/02/20/les-objets-improbables-et-delirants-de-kenji-kawakami-au-palais-de-tokyo_4580304_1655012.html?epik=dj0yJnU9bHY3clBhZVVCN2t2MmtyeDZ5NHI3RU1PMkt3ZldLUkUmcD0wJm49XzV0TWNpVmZZX3FQSEl4MjFFQWhndyZ0PUFBQUFBR2NoQTVz 

- Molleindustria Games https://www.molleindustria.org/
- Shake that Button https://shakethatbutton.com/
- Abstract Machine https://abstractmachine.net/en 
- Jan Hakon Erichsen http://www.janhakon.com/ 

**Idée :** 
- Jeu consolable seulement par les émotions faciales qui peut être bénéficier pour les handicapés. J’ai été inspiré par le jeu jouable seulement avec les  yeux : Eyes First games https://www.microsoft.com/en-us/research/product/eyes-first/ 
  - Anger for Attack
  - Fear and Disgust for Go Back
  - Happiness for Go Forward
  - Surprise for Jump
  - Sadness for Crouch

*ou Idle Game comme Universal Paperclips* 

- Alarme qu’on peut seulement éteindre avec nos sourire (pendant 3 sec) → design 
- Conversation avec l'extraterrestre (utilisation de l'IA) 
- Something with sport?


### 30.10.2024 ~ 04.11.2024
- Finir le code pour l'alarme → https://editor.p5js.org/valyong/sketches/d7zULvvOu 
- Concrétiser ma positionnement sur le sujet de recherche


### 05.11.2024
**Planning de Travail :** 
- Alarme design → INTERACTIVITÉ ET RENDU TEMPS RÉEL & GRAPHISME ET DESIGN D'INTERFACE
<img src="/img/alarme_sketch1.jpg" height="500">
- Chercher des refs pour Alarme
- Alarme écrire la description du projet
- sujet de recherche

**Ref :** 
- These 3 smart objects remind senior citizens to take pills, read without strain and stay connected! https://www.yankodesign.com/2020/07/21/these-3-smart-objects-remind-senior-citizens-to-take-pills-read-without-strain-and-stay-connected/ 
- ODDADA
- Orca by Rek & Devine https://hundredrabbits.itch.io/orca 
- (Design) Solo Radio Matches Music to Your Mood https://coolhunting.com/tech/solo-radio-mood-matches-expression/ 


Idle Game
- Candybox https://candybox2.github.io/candybox/ 
- Cookie Clicker https://orteil.dashnet.org/cookieclicker/
- Paperclips https://www.decisionproblem.com/paperclips/index2.html 
- YouTube Ego https://www.youtube.com/@ego_one 


### 12.11.2024
**Planning de Travail :** 
1. Tensorflow Lite → trouver python emotion detection 
2. Installer linux et le découvrir (Ubuntu)
3. ml5 sur linux
4. quel code faut-il utiliser (voir avec Robin) 
5. dessin design horloge mécanique (iconographique, caricaturale, machine)
6. Trouvé une horloge (le bon coin, vinted, resources AAA, etc)

**Ref :** 
- Les Temps modernes, Charlie Chaplin - smile forcé 
- Thingiverse (communauté pour 3D printing)

- How to Run TensorFlow Lite Models on Windows https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/deploy_guides/Windows_TFLite_Guide.md
- TensorFlow Lite Object Detection on Android and Raspberry Pi https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi?tab=readme-ov-file#step-3-run-tensorflow-lite-models
- How to Run TensorFlow Lite Object Detection Models on the Raspberry Pi (with Optional Coral USB Accelerator) https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/deploy_guides/Raspberry_Pi_Guide.md
- Youtube How To Run TensorFlow Lite on Raspberry Pi for Object Detection https://www.youtube.com/watch?app=desktop&v=aimSGOAUI8Y

**Ce que j'ai réalisé :** 
Test pour tflite python → détection des élements sur les images, videos et webcam
<img src="/img/animals.jpg" height="300">
<img src="/img/squirrel.jpg" height="300">
<img src="/img/webcam-test.png" height="400">

### 19.11.2024
**Ce que j'ai réalisé :** 
Python emotion detection → deep learning : 
- L'ensemble d'entraînement comprend 28 709 exemples et l'ensemble de test public comprend 3 589 exemples.
- Dataset : https://www.kaggle.com/datasets/msambare/fer2013 
- video suivi : https://www.youtube.com/watch?v=P4OevrwTq78&t=352s
- Liste de code de python: https://github.com/bnsreenu/python_for_microscopists 


Puis testé le modèle que j'ai entraîné avec le webcam : 
1. Set environment : conda activate emotion_detection / set cd 
2. Le modèle entraîné enregistré sous forme de fichier emotion_detection_model_100epochs.h5
3. Assurez-vous que les bibliothèques suivantes sont installées dans votre environnement : pip install opencv-python-headless numpy keras tensorflow
4. Code pour tester avec la webcam : emotion_webcam.py (aide de ChatGPT)
5. Exécutez le script : python emotion_webcam.py
<img src="/img/emotion-detection.png" height="400">

### 26.11.2024
**Aide**
- Par Anne-Sophie → donner un ref https://www.domesticstreamers.com/art-research/work/730-hours-of-violence/
- À Anne-Sophie → Code Processing pour glitch d'une image

**À faire**
- Tester Rasberry Pi → https://www.raspberrypi.com/documentation/computers/getting-started.html#install-an-operating-system
<img src="/img/rasberry-setting.png" height="400">

### 28.11.2024, 01.12.2024
**Ce que j'ai réalisé :** 
Python pour alarme (lance le son d'alarme et s'éteint quand il détecte Happy)
Dans python :
- pip install pygame, une bibliothèque utilisée pour créer des jeux vidéo et des applications multimédias en Python, dont je peux jouer des sonsdans divers formats (comme .mp3, .wav)
- pip install tflite-runtime

  
- source tflite1-env/bin/activate
<img src="/img/happy_detected.png" height="400">

- Installer TensorFlow Lite sur Raspberry Pi : https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/deploy_guides/Raspberry_Pi_Guide.md
<img src="/img/rasberry.jpg" height="400">
- Convert from h5 file to tflite for rasberry pi
<img src="/img/convert.png" height="200">

- Design : typo classique qui convient bien avec le thème mécanique et classique mais composition moderne et simple

<img src="/img/horloge-design1.jpg" height="240"> <img src="/img/horloge-design2.jpg" height="240">
<img src="/img/horloge-design3.jpg" height="240"> <img src="/img/horloge-design4.jpg" height="240">  
<img src="/img/horloge-design5.jpg" height="240"> 

### 03.12.2024
**À faire**
- Démonter l'alarme
- Découvrir TrouchDesigner

**Ref :** 
- Kim Le Boutin https://www.instagram.com/kimbtn_/
- Unconventional Site https://loadmo.re/
- Temporary Autonomous Zone - Hakim Bey
- Hypernormalisation | Full Documentary | Adam Curtis https://www.youtube.com/watch?v=Gr7T07WfIhM
- ENIAROF https://www.eniarof.com/
  
- PANG PANG CLUB https://pangpangclub.com/
- DISNOVATION.ORG https://disnovation.org/index.php
- _The Pirate Cinema_, Nicolas Maigret https://www.maisonpop.fr/the-pirate-cinema

**Ce que j'ai réalisé :** 
- Démonter l'alarme

<img src="/img/horloge.jpg" height="300"> <img src="/img/sketch1.jpg" height="300"> <img src="/img/sketch2.jpg" height="300">
- Tester python alarme sur rasberry pi (avec les images car il y a pas de webcam à ESAD) → ça marche
- Discuter avec Eda sur les autres sujets de recherches pour trouver l'idée. Eda m'a aider à penser sur le sujet "Comment créer des expériences contemplatives musicales".

### 10.12.2024
- tester le camera : libcamera-hello

**Ce que j'ai réalisé :** 
- imprimer le design d'alarme
- changer le script cv2.VideoCapture(0) → Picamera2 (il faut installer python3-picamera2) , car picamera2 est designer pour interagir avec libcamera
- Add the libcamera shared library path to your environment:
  export LD_LIBRARY_PATH=/usr/lib/arm-linux-gnueabihf/:$LD_LIBRARY_PATH
  export PYTHONPATH=/usr/lib/python3/dist-packages:$PYTHONPATH

cd /home/yongb/tflite1

source tflite1-env/bin/activate

export LD_LIBRARY_PATH=/usr/lib/arm-linux-gnueabihf/:$LD_LIBRARY_PATH export PYTHONPATH=/usr/lib/python3/dist-packages:$PYTHONPATH

python alarm.py

<img src="/img/picamera-success.jpg" height="500"> <img src="/img/script.jpg" height="500">

- Pourquoi détecter en Grayscale? → pour simplifier et accélérer le traitement. Les algorithmes de détection de visage (haarcascades) et les modèles de reconnaissance d'émotions se concentrent sur les formes et les contrastes, pas sur les couleurs. De plus, cela réduit la quantité de données à analyser, ce qui est essentiel pour un traitement en temps réel.
- haarcascade_frontalface_default.xml : modèle de détection de visages
Ce modèle repose sur des "caractéristiques Haar" pour analyser des motifs dans l'image (par exemple, des contrastes clairs/foncés entre les yeux et le nez).
  - https://github.com/opencv/opencv/tree/master/data/haarcascades
- emotion_detection_model.tflite : modèle d'apprentissage profond qui a été formé pour prédire les émotions à partir de l'image du visage.

### 06.01.2025
**Ce que j'ai réalisé :** 
- finalisation de monter l'horloge
- chercher comment run python script on start up in raspberry
  - https://www.samwestby.com/tutorials/rpi-startupscript.html
  - https://www.instructables.com/Raspberry-Pi-Launch-Python-script-on-startup/
- chercher comment controler DC moteur avec raspberry
  - https://youtube.com/watch?v=a99SiwFRcUI
  - https://github.com/Berardinux/DC-Motor-RaspberryPi/tree/main
- penser à l'accrochage
<img src="/img/accrochage.jpg" height="400">

### 07.01.2025
- aider Jolaine pour l'ouverture de la porte sur Unity
